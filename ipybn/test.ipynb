{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proxy: {'http': 'http://119.101.115.75:9999'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import random\n",
    "proxyHttp = [\n",
    "    {'http': 'http://119.101.115.75:9999'},\n",
    "    {'http': 'http://223.215.101.254:9999'}\n",
    "]\n",
    "proxyHttps = [\n",
    "    {'https': 'https://139.129.207.72:808'},\n",
    "    {'https': 'https://119.101.116.219:9999'}\n",
    "]\n",
    "ua1 = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'\n",
    "ua2 = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'\n",
    "head = {'User-Agent': ua2, \n",
    "             'Connection': 'keep-alive'}\n",
    "\n",
    "url = 'https://sh.zu.anjuke.com/?pi=baidu-cpchz-sh-hexin1&kwid=63651556880&utm_term=%E7%A7%9F%E6%88%BF'\n",
    "url1 = 'http://139.224.115.177:7777'\n",
    "url2 = 'https://icanhazip.com'\n",
    "url3 = 'https://www.toutiao.com/'\n",
    "proxy = random.choice(proxyHttp)\n",
    "print('proxy:',proxy)\n",
    "# p = requests.get(url1, headers=head, proxies = proxy)\n",
    "# p = requests.get(url3, headers=head)\n",
    "# print(p.text)\n",
    "# print(p.select('.single-mode-rbox'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最简单的爬虫程序demo , 适用于静态的,没有防爬虫策略的网站\n",
    "\n",
    "import requests # 发送网络请求，获取响应内容\n",
    "from bs4 import BeautifulSoup  # 对于网站响应的html进行解析 和数据的清洗\n",
    "import pandas # 数据可视化，保存数据\n",
    "\n",
    "def simpleDemo():\n",
    "    url = 'https://news.qudong.com/yejie/' # 要爬取的网页的网站\n",
    "\n",
    "    # 1 获取网页内容\n",
    "    req = requests.get(url) # 进行网络请求，获取响应的内容\n",
    "    req.encoding = 'utf8' # 设置解析编码,防止中文乱码\n",
    "    contentAll = req.text # 解析为文本\n",
    "\n",
    "    # 2 清洗数据，处理\n",
    "    soup = BeautifulSoup(contentAll,'html.parser') # 创建 beautifulsoup对象\n",
    "    contentList = soup.select('.text h4 ') # 根据css帅选数据,得到一个嵌套着beautifulsoup对象的列表\n",
    "    # 为了更好的进行数据的保存与展示，将数据保存在嵌套字典的列表里\n",
    "    all = [] # \n",
    "    for item in contentList: # 循环获取文本数据\n",
    "        all.append({'title':item.text}) \n",
    "\n",
    "    # 3 保存数据\n",
    "    # 使用pandas库函数，将数据导入excel\n",
    "    all = pandas.DataFrame(all)\n",
    "    all.to_excel('./temp/content.xlsx')\n",
    "    # print(all)\n",
    "simpleDemo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加代理\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas \n",
    "\n",
    "def addProxy():\n",
    "    # 设置代理ip，防止本地ip被封\n",
    "    proxyHttps = {'https': 'https://139.129.207.72:808'}\n",
    "    # 设置ua,伪装成游览器\n",
    "    userAgent = 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'\n",
    "    head = {'User-Agent': userAgent,\n",
    "            'Connection': 'keep-alive'}\n",
    "\n",
    "    # 1 获取网页内容\n",
    "    # req = requests.get(url3, headers=head, proxies = proxy)  # 免费的ip代理，速度比较慢，我就不用了\n",
    "    url = 'https://sh.lianjia.com/ershoufang/?utm_source=baidu&utm_medium=pinzhuan&utm_term=biaoti&utm_content\\\n",
    "            =biaotimiaoshu&utm_campaign=sousuo&ljref=pc_sem_baidu_ppzq_x'\n",
    "    req = requests.get(url, headers=head)\n",
    "    req.encoding = 'utf8' # 设置解析编码,防止中文乱码\n",
    "    contentAll = req.text # 解析为文本\n",
    "\n",
    "    # 2 清洗数据，处理\n",
    "    soup = BeautifulSoup(contentAll,'html.parser') # 创建 beautifulsoup对象\n",
    "    contentList = soup.select('.info.clear .title a') # 根据css帅选数据,得到一个嵌套着beautifulsoup对象的列表\n",
    "\n",
    "    all = []\n",
    "    for item in contentList:\n",
    "        all.append({'title':item.text})\n",
    "\n",
    "    # 3 保存数据\n",
    "    all = pandas.DataFrame(all)\n",
    "    all.to_excel('./temp/content.xlsx')\n",
    "    # print(all)\n",
    "addProxy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -- 中国共产党第十九届中央纪律检查委员会第三次全体会议公报\n",
      "2 -- 预告｜电视专题片《红色通缉》第四集《携手》13日晚“八点档”播出\n",
      "3 -- 伤娃利器！央视曝光儿童推车增塑剂残留超标稳定性合格率为零\n",
      "4 -- 消防车因超载被罚，中国消防：非营运特种车不应按普通车标准\n",
      "5 -- 微信8年，干掉了短信也杀死了媒体\n",
      "6 -- 台湾刚装备“反北斗卫星”装置，解放军已提前做好准备\n",
      "7 -- 罗文嘉出任民进党秘书长淡出政坛前曾在陈水扁手下任职多年\n",
      "8 -- 甘肃民营企业家冤狱11年获平反，约21亿国家赔偿申请遭拒\n",
      "9 -- 活不见人死不见尸，“消失”24年的儿子突然回来了……\n",
      "10 -- 波兰安全部门：逮捕中国公民因个人行为，与华为没有直接关联\n",
      "11 -- 好暖！民警急需救命血寒风刺骨天有人穿着睡衣就赶来了！\n",
      "12 -- 不在容颜最盛时却意外红遍全球的她，拥有怎样的变色龙式美貌？\n",
      "13 -- 柳州“善心女孩”伤势过重不幸离世她的事迹感动了无数市民，其家属向大家表示感谢\n",
      "14 -- 变态版传奇，上线就送VIP，爆率高，回收快，元宝在线可交易！\n",
      "15 -- 别了长江渔火！明年年底前长江全面退捕初定禁捕十年\n",
      "16 -- 80年代的小朋友，纯真得看了想哭，长大的你我，再也回不到过去\n",
      "17 -- 广西龙脊梯田景区发生山体崩塌\n",
      "18 -- 找普京签合约？俄罗斯开出的条件让日本感到绝望，非常值得学习\n",
      "19 -- Qnews｜海南警方通报“想给新生儿落户跑5趟”：涉事民警致歉并被调岗\n",
      "20 -- 家中宽带时好时坏，这是为什么，原因找到了！\n",
      "21 -- 80后民主党女议员决意挑战特朗普，宣布参加2020年美国总统竞选\n",
      "22 -- 神木矿难致21人死亡，涉事煤矿刚刚通过安全生产验收\n",
      "23 -- 山东多地流感高发！儿科爆满！专家提醒：今年多甲流，打针意义不大\n",
      "24 -- “大理寺”是一个审判机构，为什么被称为“寺”？\n",
      "25 -- 这位广州护士，你在动车上俯身救人的样子，被写到了感谢信里\n",
      "26 -- 马云为20位乡村校长颁奖这个小细节让万人点赞！\n",
      "27 -- 普京同意放人了，乌24名被扣船员有救，交换条件让波罗申科难受\n",
      "28 -- 别再玩假传奇了，这款传奇爆率9.8，你找到充值入口算我输！\n",
      "29 -- 孩子要经历什么，才能懂得学业的重要、父母的不易？\n",
      "30 -- 科学研究证明，保持适度饥饿，确实能活的更久\n",
      "31 -- 马云任主席、马化腾任副主席，将协助完成中央赋予的重大使命\n",
      "32 -- 陕西神木李家沟煤矿21名遇难者遗体全部升井\n",
      "33 -- 因为身体缺陷，她成了万米高空坠落活下的第一人\n",
      "34 -- 亚洲杯变武打片？朝鲜连续丢球心态崩了：4分钟3次恶劣犯规！\n",
      "35 -- 男子无证驾驶上高速被查后拿出假证忽悠！结果多掏出一本\n",
      "36 -- 天寒地冻：东北刨冰挖蛏人\n",
      "37 -- 许家印回河南老家一个月后，捐资3亿兴建的新高中已破土动工\n",
      "38 -- 90后帅小哥用2元圆珠笔画出惊艳世作，狂吸粉80万！\n",
      "39 -- 10张历年春运图片，都是母亲带小孩，看到第几张你被感动了？\n",
      "40 -- 崔天凯在美国谈《告台湾同胞书》：中国人的事中国人决定\n",
      "41 -- 腊八腌蒜为啥会变绿？变绿后的大蒜营养会变化吗？\n",
      "42 -- 陈小春坦言：这游戏不充钱都能当全服大哥，找到充值入口算我输！\n",
      "43 -- 男子高考落榜致精神失常亲人去世后无人照顾村民轮流送饭14年\n",
      "44 -- 国民党纪念蒋经国逝世31周年，蒋万安缺席\n",
      "45 -- 6年打造50艘千吨级轻护：我国为何要建这么多056型护卫舰？\n",
      "46 -- 陕西神木矿难致21人死亡，类似事故并非首次\n",
      "47 -- 绿萝喝这“3种”酸水，几天喂一次，叶子绿得能滴油！\n",
      "48 -- 北京城市副中心党工委、管委会成立！隋振江兼任书记、主任\n",
      "49 -- 云南：1家4口凌晨翻车坠崖4岁男童赤脚爬上山求救救出1岁半妹妹\n",
      "50 -- 几个月前宣布证明黎曼猜想的那个人去世，注意的人并不太多\n",
      "51 -- 四川金口河：神秘的虚恨部，四川至今唯一不对“外”开放地区\n",
      "52 -- 韩国瑜自曝被民进党“追杀”妻子学校门口遭威胁\n",
      "53 -- 俩奔驰车尾号都是“6666”，交警多看一眼引出套牌奇案\n",
      "54 -- 为什么说人缘越好，反而混得越差？背后原因太厚黑，值得一看！\n",
      "55 -- 新余原市长董晓健当选人大常委会主任，此前已任党组书记\n",
      "56 -- 说传奇已死，肯定没玩过这款，爆率9.8，有VIP充值算你赢！\n",
      "57 -- 朝鲜战场最牛战例：全歼美军精锐王牌“北极熊团”！缴获的团旗差点被用做“蒸笼布”\n",
      "58 -- 重庆一消防车走高速因超载被罚，交通执法部门回应：正核实\n",
      "59 -- 卢希当选为中央纪委常委，曾任最高检反贪污贿赂总局局长\n",
      "60 -- 取消年检，利大还是弊大？网友：有多少交通事故是跟年检有关的？\n",
      "61 -- 今天不可能再有匠人用这种方式来建造如此惊险的大桥了｜一席\n",
      "62 -- 这是蒜蓉大虾的家常做法，比蒸出来的好吃，简单易做，越吃越香\n",
      "63 -- 公安的摄像头每天都拍到什么？答案令人大吃一惊！\n",
      "64 -- 世界上最豪华的监狱只有115名罪犯，除了自由啥都有\n",
      "65 -- 李荣浩丢平板电脑，望拾到者不要将资料发网上\n",
      "66 -- 他的去世弄哭了全城人……5年送出6万碗面，杭州这家「免费」面馆的命运让人心碎\n"
     ]
    }
   ],
   "source": [
    "# 终结篇\n",
    "# 说明：\n",
    "# 1. selenium是一款用来做自动化测试的工具，可以通过加载游览器的驱动控制游览器，在这里用来控制游览器访问网页爬取数据\n",
    "\n",
    "# 2. User Agent 是根据 操作系统，CPU，游览器类型 形成的\n",
    "\n",
    "# 模拟游览器爬取动态网页\n",
    "# !pip install selenium\n",
    "from bs4 import BeautifulSoup\n",
    "# from selenium import webdriver\n",
    "import selenium\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import random\n",
    "import pandas\n",
    "driverPath = 'D:/Python/chromedriver.exe'\n",
    "userAgent1 = 'Mozilla/5.0(compatible;MSIE9.0;WindowsNT6.1;Trident/5.0'\n",
    "# OPPO A57\t Android\t手机百度\n",
    "userAgent2 = 'Mozilla/5.0 (Linux; Android 6.0.1; OPPO A57 Build/MMB29M; wv) AppleWebKit/537.36(KHTML, like Gecko) Version/4.0 Chrome/63.0.3239.83 Mobile Safari/537.36 T7/10.13 baiduboxapp/10.13.0.10 (Baidu; P1 6.0.1)'\n",
    "\n",
    "chromeOptions = Options()\n",
    "# 设置游览器代理\n",
    "chromeOptions.add_argument('user-agent=' + userAgent1)\n",
    "chromeOptions.add_argument('disable-infobars') \n",
    "# 设置不加载图片\n",
    "prefs = {\"profile.managed_default_content_settings.images\": 2} \n",
    "chromeOptions.add_experimental_option(\"prefs\", prefs) \n",
    "# 不显示游览器\n",
    "chromeOptions.add_argument('--headless') \n",
    "chromeOptions.add_argument('--disable-gpu')\n",
    "# ipProxy = 'http://110.52.235.99:9999'\n",
    "# chromeOptions.add_argument(\"--proxy-server=\" + ipProxy) # 设置ip代理\n",
    "browser = webdriver.Chrome(executable_path = driverPath, options = chromeOptions) # 获取游览器的驱动\n",
    "browser.implicitly_wait(10)  # 隐式等待10 s，即最长等待元素加载时间为10s并且一旦发现元素加载成功则执行，全局有效\n",
    "url3 = 'http://httpbin.org/ip'\n",
    "url4 = 'https://www.toutiao.com/'\n",
    "browser.get(url4)\n",
    "# 循环下拉加载10次\n",
    "height = browser.execute_script('return screen.height')\n",
    "for _ in range(10):\n",
    "    sleepTime = random.uniform(1.1,3.0) # 生成浮点型随机数\n",
    "    time.sleep(sleepTime) # 强制等待，防止加载过快，触发服务端防爬虫机制\n",
    "    js='var q=document.documentElement.scrollTop=' + str(height)\n",
    "    browser.execute_script(js)\n",
    "    height += 700\n",
    "# content = browser.find_elements_by_css_selector('.link.title')\n",
    "content = browser.find_elements_by_xpath(\"//a[@class='link title']\")\n",
    "for item in content:\n",
    "    print(content.index(item)+1,'--',item.text.replace(' ','').replace('\\n',''))\n",
    "browser.close() # 关闭浏览器\n",
    "browser.quit() # 关闭chreomedriver进程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome_options.add_argument('--headless') 不显示游览器\n",
    "# chrome_options.add_argument('--disable-gpu')\n",
    "# chrome_options.add_argument('disable-infobars') \n",
    "\n",
    "# html = browser.execute_script(\"return document.documentElement.outerHTML\") 执行js代码\n",
    "# html = browser.find_elements_by_css_selector('.main-list')[0].get_attribute('innerHTML') 获取html\n",
    "\n",
    "# 不加载图片\n",
    "# prefs = {\"profile.managed_default_content_settings.images\": 2}  \n",
    "# chrome_options.add_experimental_option(\"prefs\", prefs) \n",
    "\n",
    "# options.setCapability(\"proxy\", proxy) 设置代理\n",
    "# driver.find_element_by_id('').send_keys('') 填写表单\n",
    "# stime = driver.find_elements_by_css_selector('.c_tx.c_tx3.goDetail') css选择器\n",
    "# driver.find_element_by_link_text('下一页').click() 通过文本选择\n",
    "# driver.switch_to.frame('app_canvas_frame') 进入网页内置的ifrane\n",
    "# driver.save_screenshot(\"baidu.png\") 生成网页图片\n",
    "# driver.page_source 获取网页源码\n",
    "# driver.get_cookies() \n",
    "# from selenium.webdriver.common.action_chains import ActionChains  是一个底层的自动交互的方法库，例如鼠标移动、鼠标按键事件、键盘响应和菜单右击交互。\n",
    "\n",
    "# driver.find_element_by_id(\"kw\").send_keys(Keys.CONTROL, 'a') ctrl+a 全选输入框内容\n",
    "# driver.find_element_by_id(\"kw\").send_keys(Keys.CONTROL, 'x') ctrl+x 剪切输入框内容\n",
    "\n",
    "# from selenium.webdriver.common.keys import Keys 键盘按键操作的keys包\n",
    "# driver.find_element_by_id(\"su\").send_keys(Keys.RETURN) 模拟Enter回车键\n",
    "\n",
    "# from selenium.webdriver.support import expected_conditions as EC  selenium的判断模块，例如判断是否存在某个元素\n",
    "# from selenium.webdriver.support.wait import WebDriverWait 显示等待模块\n",
    "\n",
    "# js\n",
    "# window.screen.availHeight 返回当前屏幕高度(空白空间) \n",
    "# window.screen.height 返回当前屏幕高度(分辨率值) \n",
    "# document.documentElement.clientHeight => 就是网页在浏览器中可见高度，不包括浏览器自身的状态栏，随着浏览器大小变化；\n",
    "# window.document.body.offsetHeight; 返回当前网页高度 \n",
    "# document.body.scrollHeight 返回当前网页高度 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
